{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "##!pip install transformers==3.0.0\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from transformers import AutoModel\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Specify the GPU\n",
    "# Setting up the device for GPU usage\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert Model\n",
    "\n",
    "# for binary class\n",
    "class BERT_Bi_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Bi_Arch, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=1) \n",
    "        self.lstm = nn.LSTM(768, 256, batch_first=True,bidirectional=True)\n",
    "        self.linear = nn.Linear(256*2, 2)       \n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "        sequence_output, pooled_output = self.bert(sent_id, attention_mask=mask)\n",
    "\n",
    "        # sequence_output has the following shape: (batch_size, sequence_length, 768)\n",
    "        lstm_output, (h,c) = self.lstm(sequence_output) ## extract the 1st token's embeddings\n",
    "        hidden = torch.cat((lstm_output[:,-1, :256],lstm_output[:,0, 256:]),dim=-1)\n",
    "        linear_output = self.linear(hidden.view(-1,256*2))\n",
    "        return self.softmax(linear_output)\n",
    "    \n",
    "\n",
    "# for multiclass\n",
    "class BERT_Multi_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Multi_Arch, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    " \n",
    "        self.softmax = nn.LogSoftmax(dim=1) \n",
    "        self.lstm = nn.LSTM(768, 256, batch_first=True,bidirectional=True)\n",
    "        self.linear = nn.Linear(256*2, 3)\n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "        sequence_output, pooled_output = self.bert(sent_id, attention_mask=mask)\n",
    "\n",
    "        # sequence_output has the following shape: (batch_size, sequence_length, 768)\n",
    "        lstm_output, (h,c) = self.lstm(sequence_output) ## extract the 1st token's embeddings\n",
    "        hidden = torch.cat((lstm_output[:,-1, :256],lstm_output[:,0, 256:]),dim=-1)\n",
    "        linear_output = self.linear(hidden.view(-1,256*2)) \n",
    "        return self.softmax(linear_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Functions\n",
    "def read_dataset(task):\n",
    "    \n",
    "    df = pd.read_csv('movieCorpus.csv')\n",
    "    \n",
    "    train = df.loc[df['Test'] == 0] #pd.read_csv(\"trainData.csv\")\n",
    "    test = df.loc[df['Test'] == 1] #pd.read_csv(\"evaluation.csv\")\n",
    "    \n",
    "    train_subj = train.copy()\n",
    "    test_subj = test.copy()\n",
    "    \n",
    "    def change_subj_labels(data):\n",
    "        group_subj = {\"OBJECTIVE\":0, \"SUBJECTIVE\":1}\n",
    "        data['Auto_labeller_eval_subj'] = data['Auto_labeller_eval_subj'].apply(lambda x: group_subj[x])\n",
    "        return data['Auto_labeller_eval_subj']\n",
    "\n",
    "    train_subj['Auto_labeller_eval_subj'] = change_subj_labels(train_subj)\n",
    "    test_subj['Auto_labeller_eval_subj'] = change_subj_labels(test_subj)\n",
    "    \n",
    "    \n",
    "    train_pol = train.loc[train['Auto_labeller_eval_subj'] == \"SUBJECTIVE\"]\n",
    "    test_pol = test.loc[test['Auto_labeller_eval_subj'] == \"SUBJECTIVE\"]\n",
    "    \n",
    "    def change_pol_labels(data):\n",
    "        group_pol = {\"NEGATIVE\":0, \"POSITIVE\":1, \"NEUTRAL\":2, \"None\":\"None\"}\n",
    "        data['Auto_labeller_eval_pol'] = data['Auto_labeller_eval_pol'].apply(lambda x: group_pol[x])\n",
    "        return data['Auto_labeller_eval_pol']\n",
    "    \n",
    "    train_pol['Auto_labeller_eval_pol'] = change_pol_labels(train_pol)\n",
    "    test_pol['Auto_labeller_eval_pol'] = change_pol_labels(test_pol)    \n",
    "    \n",
    "    keep_col = ['body', 'Auto_labeller_eval_subj', 'Auto_labeller_eval_pol']\n",
    "    train_subj = train_subj[keep_col]\n",
    "    test_subj = test_subj[keep_col]\n",
    "    train_pol = train_pol[keep_col]\n",
    "    test_pol = test_pol[keep_col]\n",
    "    \n",
    "    if task == \"s\":\n",
    "        return train_pol['body'].tolist(), train_pol['Auto_labeller_eval_pol'],\\\n",
    "               test_pol['body'].tolist(), test_pol['Auto_labeller_eval_pol']\n",
    "\n",
    "    elif task == \"o\":\n",
    "        return train_subj['body'].tolist(), train_subj['Auto_labeller_eval_subj'],\\\n",
    "               test_subj['body'].tolist(), test_subj['Auto_labeller_eval_subj']\n",
    "\n",
    "    elif task == \"getDataSubj\":\n",
    "        test_subj['Auto_labeller_eval_pol'] = change_pol_labels(test_subj)\n",
    "        return test_subj\n",
    "    \n",
    "    elif task == \"getDataPol\":\n",
    "        test_pol['Auto_labeller_eval_subj'] = change_subj_labels(test_pol)\n",
    "        return test_pol\n",
    "\n",
    "def pre_process_dataset(values):\n",
    "    new_values = list()\n",
    "    \n",
    "    for value in values:\n",
    "        new_values.append(value)\n",
    "    return new_values\n",
    "\n",
    "\n",
    "def data_process(data, labels):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    for sentence in data:\n",
    "        bert_inp = bert_tokenizer.__call__(sentence, max_length=150,\n",
    "                                           padding='max_length', pad_to_max_length=True,\n",
    "                                           truncation=True, return_token_type_ids=False)\n",
    "\n",
    "        input_ids.append(bert_inp['input_ids'])\n",
    "        attention_masks.append(bert_inp['attention_mask'])\n",
    "\n",
    "    input_ids = np.asarray(input_ids)\n",
    "    attention_masks = np.array(attention_masks)\n",
    "    labels = np.array(labels)\n",
    "    return input_ids, attention_masks, labels\n",
    "\n",
    "\n",
    "def load_and_process(task):\n",
    "    train_data, train_labels, test_data, test_labels = read_dataset(task)\n",
    "\n",
    "    train_input_ids, train_attention_masks, train_labels = data_process(pre_process_dataset(train_data), train_labels)\n",
    "    test_input_ids, test_attention_masks, test_labels = data_process(pre_process_dataset(test_data), test_labels)\n",
    "\n",
    "    return train_input_ids, train_attention_masks, train_labels,\\\n",
    "           test_input_ids, test_attention_masks, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model Function\n",
    "def train(model, loss_function, batch_size, train_dataloader, task, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    total = len(train_dataloader)\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "\n",
    "        step = i+1\n",
    "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
    "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
    "        filledLength = int(100 * step // total)\n",
    "        bar = 'â–ˆ' * filledLength + '>'  *(filledLength < 100) + '.' * (99 - filledLength)\n",
    "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}', end='') # accuracy={total_accuracy}\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        del batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # clear previously calculated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "        \n",
    "        # make sure it labels are int64 type\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = loss_function(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss += float(loss.item())\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        #preds = preds.detach().cpu().numpy()\n",
    "\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds.detach().cpu().numpy())\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / (len(train_dataloader)*batch_size)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    # returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(task):\n",
    "    \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Run Data Functions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Load Data-set ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    train_input_ids, train_attention_masks, train_labels,\\\n",
    "    test_input_ids, test_attention_masks, test_labels = load_and_process(task)\n",
    "\n",
    "    train_df = pd.DataFrame(list(zip(train_input_ids, train_attention_masks)), columns=['input_ids', 'attention_masks'])\n",
    "    test_df = pd.DataFrame(list(zip(test_input_ids, test_attention_masks)), columns=['input_ids', 'attention_masks'])\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~ Import BERT Model and BERT Tokenizer ~~~~~~~~~~~~~~~~~~~~~#\n",
    "    bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Tokenization ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    # for train set\n",
    "    train_seq = torch.tensor(train_df['input_ids'].tolist())\n",
    "    train_mask = torch.tensor(train_df['attention_masks'].tolist())\n",
    "    train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "    # for test set\n",
    "    test_seq = torch.tensor(test_df['input_ids'].tolist())\n",
    "    test_mask = torch.tensor(test_df['attention_masks'].tolist())\n",
    "    test_y = torch.tensor(test_labels.tolist())\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Create DataLoaders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "    # define a batch size\n",
    "    batch_size = 32\n",
    "\n",
    "    # wrap tensors\n",
    "    train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "    # sampler for sampling the data during training\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "\n",
    "    # dataLoader for train set\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    return bert, batch_size,\\\n",
    "           train_dataloader,\\\n",
    "           train_y, test_y,\\\n",
    "           train_seq, test_seq,\\\n",
    "           train_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Run Model Functions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "def run_model(task='s', epochs=3):\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Load Data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    bert, batch_size,\\\n",
    "    train_dataloader,\\\n",
    "    _, test_y,\\\n",
    "    _, test_seq,\\\n",
    "    _, test_mask= load_data(task)\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    \n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Freeze BERT Parameters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    # freeze all the parameters\n",
    "    for param in bert.parameters():\n",
    "        param.requires_grad = False\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    # pass the pre-trained BERT to our define architecture\n",
    "    if task=='s':\n",
    "        model = BERT_Multi_Arch(bert)\n",
    "    else:\n",
    "        model = BERT_Bi_Arch(bert)\n",
    "        \n",
    "    # push the model to GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # optimizer from hugging face transformers\n",
    "    from transformers import AdamW\n",
    "\n",
    "    # define the optimizer\n",
    "#     optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr = 5e-5, #5e-5 is the best setting so dat. 70% accuracy\n",
    "        eps = 1e-8\n",
    "    )\n",
    "\n",
    "    # loss function\n",
    "    loss_function = nn.NLLLoss()\n",
    "\n",
    "    # set initial loss to infinite\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    epochs = epochs\n",
    "    current = 1\n",
    "    train_loss_list = []\n",
    "    # for each epoch\n",
    "    while current <= epochs:\n",
    "\n",
    "        print(f'\\nEpoch {current} / {epochs}:')\n",
    "\n",
    "        # train model\n",
    "        train_loss, _ = train(model, loss_function, batch_size, train_dataloader, task, optimizer)\n",
    "        train_loss_list.append(train_loss)\n",
    "        # evaluate model\n",
    "#         valid_loss, _ = evaluate(model, loss_function, batch_size, val_dataloader, task)\n",
    "\n",
    "        # save the best model\n",
    "        if task == \"s\" and os.path.isfile('polarityBertBiLSTM.pth') == False:\n",
    "            torch.save(model.state_dict(), 'polarityBertBiLSTM.pth')\n",
    "            best_loss = train_loss_list[current-1]\n",
    "        if task == \"o\" and os.path.isdir('subjectivityBertBiLSTM.pth') == False:\n",
    "            torch.save(model.state_dict(), 'subjectivityBertBiLSTM.pth')\n",
    "            best_loss = train_loss_list[current-1]\n",
    "            \n",
    "        if len(train_loss_list) > 1:\n",
    "            if train_loss_list[current-1] < best_loss:\n",
    "                best_loss = train_loss_list[current-1]\n",
    "\n",
    "                if task == \"s\":\n",
    "                    torch.save(model.state_dict(), 'polarityBertBiLSTM.pth')\n",
    "                elif task == \"o\":\n",
    "                    torch.save(model.state_dict(), 'subjectivityBertBiLSTM.pth')\n",
    "                \n",
    "                    \n",
    "        print(f'\\n\\nTraining Loss: {train_loss:.3f}')\n",
    "\n",
    "        current = current + 1\n",
    "    \n",
    "    else:\n",
    "        #print(\"Got weights!\")\n",
    "        # load weights of best model\n",
    "        if task == \"s\":\n",
    "            print(\"Loading polarity weights...\")\n",
    "            model.load_state_dict(torch.load(\"polarityBertBiLSTM.pth\"))\n",
    "            print(\"Loaded polarity weights!\")\n",
    "\n",
    "        elif task == \"o\":\n",
    "            print(\"Loading subjectivity weights...\")\n",
    "            model.load_state_dict(torch.load(\"subjectivityBertBiLSTM.pth\"))        \n",
    "            print(\"Loaded subjectivity weights!\")\n",
    "            \n",
    "#         model.load_state_dict(torch.load(\"/content/drive/MyDrive/saved_weights.pth\"), strict=False)\n",
    "\n",
    "    # get predictions for test data\n",
    "    print(\"\\nPredicting Results...\")\n",
    "    model.eval()\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        preds = model(test_seq.to(device), test_mask.to(device))\n",
    "        end = time.time()\n",
    "        print(\"Time taken to predict: \", end - start)\n",
    "        \n",
    "        preds = preds.detach().cpu().numpy()\n",
    "\n",
    "    # model performance on test dataset\n",
    "    print(\"\\nTest Performance for Task \"+task+\":\")\n",
    "\n",
    "    ## precision_recall_fscore_support:\n",
    "    ### micro: balanced dataset\n",
    "    ### macro: imbalanced dataset where all classes are equally important\n",
    "    ### weighted: imbalanced dataset but want to assign greater contribution to classes with more examples in the dataset\n",
    "    ### binary: binary classfication - Only report results for the class specified by pos_label\n",
    "    if task == 's':\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        precision, recall, fscore, _ = precision_recall_fscore_support(test_y, preds, average='macro')\n",
    "    else:\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        precision, recall, fscore, _ = precision_recall_fscore_support(test_y, preds, average='macro')\n",
    "        \n",
    "    ## accuracy score\n",
    "    accuracy = accuracy_score(test_y, preds)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {fscore}\")\n",
    "    \n",
    "    print(classification_report(test_y, preds))\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading polarity weights...\n",
      "Loaded polarity weights!\n",
      "\n",
      "Predicting Results...\n",
      "Time taken to predict:  503.9818260669708\n",
      "\n",
      "Test Performance for Task s:\n",
      "Accuracy: 0.8840579710144928\n",
      "Precision: 0.8597478791037672\n",
      "Recall: 0.8674814116461974\n",
      "F1-score: 0.8628865610573335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93       493\n",
      "           1       0.94      0.91      0.92       710\n",
      "           2       0.70      0.78      0.74       315\n",
      "\n",
      "    accuracy                           0.88      1518\n",
      "   macro avg       0.86      0.87      0.86      1518\n",
      "weighted avg       0.89      0.88      0.89      1518\n",
      "\n",
      "Loading subjectivity weights...\n",
      "Loaded subjectivity weights!\n",
      "\n",
      "Predicting Results...\n",
      "Time taken to predict:  728.5104732513428\n",
      "\n",
      "Test Performance for Task o:\n",
      "Accuracy: 0.9048498845265589\n",
      "Precision: 0.9165374779003477\n",
      "Recall: 0.8545496290775505\n",
      "F1-score: 0.8780448455017773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.73      0.82       647\n",
      "           1       0.89      0.98      0.94      1518\n",
      "\n",
      "    accuracy                           0.90      2165\n",
      "   macro avg       0.92      0.85      0.88      2165\n",
      "weighted avg       0.91      0.90      0.90      2165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run everything\n",
    "tasks_list = ['s','o']\n",
    "preds_list = []\n",
    "\n",
    "for task in tasks_list:\n",
    "    # parameters:\n",
    "    ## task: 's' for sentiment, 'o' for opinion (default 's')\n",
    "    ## epochs: number of epochs when training model (default 3, to load saved weights enter 0)\n",
    "    preds = run_model(task=task, epochs=0)\n",
    "    preds_list.append(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 1, ..., 2, 2, 2], dtype=int64),\n",
       " array([1, 1, 1, ..., 0, 0, 0], dtype=int64)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_pol = preds_list[0].tolist()\n",
    "pol = read_dataset(\"getDataPol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>Auto_labeller_eval_subj</th>\n",
       "      <th>Auto_labeller_eval_pol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19284</th>\n",
       "      <td>Serenity with Anne Hathaway and Resort to Love...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19286</th>\n",
       "      <td>Dammit I kept saying she reminded me of someon...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19288</th>\n",
       "      <td>No it's CGI, like Dude, in Free Guy.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19290</th>\n",
       "      <td>Right? or that Jungle Cruise redefined some ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19292</th>\n",
       "      <td>Oh yeah, bringing the birthday cake to him whi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  \\\n",
       "19284  Serenity with Anne Hathaway and Resort to Love...   \n",
       "19286  Dammit I kept saying she reminded me of someon...   \n",
       "19288               No it's CGI, like Dude, in Free Guy.   \n",
       "19290  Right? or that Jungle Cruise redefined some ge...   \n",
       "19292  Oh yeah, bringing the birthday cake to him whi...   \n",
       "\n",
       "       Auto_labeller_eval_subj  Auto_labeller_eval_pol  \n",
       "19284                        1                       1  \n",
       "19286                        1                       1  \n",
       "19288                        1                       1  \n",
       "19290                        1                       2  \n",
       "19292                        1                       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>Auto_labeller_eval_subj</th>\n",
       "      <th>Auto_labeller_eval_pol</th>\n",
       "      <th>Classification Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19284</th>\n",
       "      <td>Serenity with Anne Hathaway and Resort to Love...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19286</th>\n",
       "      <td>Dammit I kept saying she reminded me of someon...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19288</th>\n",
       "      <td>No it's CGI, like Dude, in Free Guy.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19290</th>\n",
       "      <td>Right? or that Jungle Cruise redefined some ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19292</th>\n",
       "      <td>Oh yeah, bringing the birthday cake to him whi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  \\\n",
       "19284  Serenity with Anne Hathaway and Resort to Love...   \n",
       "19286  Dammit I kept saying she reminded me of someon...   \n",
       "19288               No it's CGI, like Dude, in Free Guy.   \n",
       "19290  Right? or that Jungle Cruise redefined some ge...   \n",
       "19292  Oh yeah, bringing the birthday cake to him whi...   \n",
       "\n",
       "       Auto_labeller_eval_subj  Auto_labeller_eval_pol  Classification Results  \n",
       "19284                        1                       1                       1  \n",
       "19286                        1                       1                       1  \n",
       "19288                        1                       1                       1  \n",
       "19290                        1                       2                       2  \n",
       "19292                        1                       0                       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol['Classification Results'] = pred_pol\n",
    "pol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol.to_csv(\"BertBiLSTM_polarityClassificationResults.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_subj = preds_list[1].tolist()\n",
    "subj = read_dataset(\"getDataSubj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>Auto_labeller_eval_subj</th>\n",
       "      <th>Auto_labeller_eval_pol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19284</th>\n",
       "      <td>Serenity with Anne Hathaway and Resort to Love...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19286</th>\n",
       "      <td>Dammit I kept saying she reminded me of someon...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19288</th>\n",
       "      <td>No it's CGI, like Dude, in Free Guy.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19290</th>\n",
       "      <td>Right? or that Jungle Cruise redefined some ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19292</th>\n",
       "      <td>Oh yeah, bringing the birthday cake to him whi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  \\\n",
       "19284  Serenity with Anne Hathaway and Resort to Love...   \n",
       "19286  Dammit I kept saying she reminded me of someon...   \n",
       "19288               No it's CGI, like Dude, in Free Guy.   \n",
       "19290  Right? or that Jungle Cruise redefined some ge...   \n",
       "19292  Oh yeah, bringing the birthday cake to him whi...   \n",
       "\n",
       "       Auto_labeller_eval_subj Auto_labeller_eval_pol  \n",
       "19284                        1                      1  \n",
       "19286                        1                      1  \n",
       "19288                        1                      1  \n",
       "19290                        1                      2  \n",
       "19292                        1                      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj['Classification Results'] = pred_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj.to_csv(\"BertBiLSTM_subjectivityClassificationResults.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References<br>https://github.com/Rachel-loo/BERT-BiLSTM/blob/main/models/bert_BiLSTM.py<br>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNAH18fNerSp+olcSBcN+Sm",
   "include_colab_link": true,
   "mount_file_id": "1vj3Z4UpPYqCamgeWQiN11TteiazAwTt5",
   "name": "BertCnnFinal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
